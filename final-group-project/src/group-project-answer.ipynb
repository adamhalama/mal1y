{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Group Assignment & Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__You should be able to start up on this exercise after Lecture 1.__\n",
    "\n",
    "*This exercise must be a group effort. That means everyone must participate in the assignment.*\n",
    "\n",
    "In this assignment you will solve a data science problem end-to-end, pretending to be recently hired data scientists in a company. To help you get started, we've prepared a checklist to guide you through the project. Here are the main steps that you will go through:\n",
    "\n",
    "1. Frame the problem and look at the big picture\n",
    "2. Get the data\n",
    "3. Explore and visualise the data to gain insights\n",
    "4. Prepare the data to better expose the underlying data patterns to machine learning algorithms\n",
    "5. Explore many different models and short-list the best ones\n",
    "6. Fine-tune your models\n",
    "7. Present your solution \n",
    "\n",
    "In each step we list a set of questions that one should have in mind when undertaking a data science project. The list is not meant to be exhaustive, but does contain a selection of the most important questions to ask. We will be available to provide assistance with each of the steps, and will allocate some part of each lesson towards working on the projects.\n",
    "\n",
    "Your group must submit a _**single**_ Jupyter notebook, structured in terms of the first 6 sections listed above (the seventh will be a video uploaded to some streaming platform, e.g. YouTube, Vimeo, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analysis: Frame the problem and look at the big picture\n",
    "1. Find a problem/task that everyone in the group finds interesting\n",
    "2. Define the objective in business terms\n",
    "3. How should you frame the problem (supervised/unsupervised etc.)?\n",
    "4. How should performance be measured?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Identifying an Interesting Problem/Task\n",
    "As a team of newly hired data scientists at MetaData Inc.,(Meta), we have identified a crucial and challenging task: analyzing user post content for sentiment. Our goal is to understand the general mood and opinions expressed by users on the platform. This is particularly important for MetaData, as it can provide insights into user engagement, detect emerging trends, and even identify potential areas of concern (like the spread of negative sentiment or harmful content which of course we personally dont like).\n",
    "\n",
    "##### 2. Defining the Objective in Business Terms\n",
    "The primary business objective of our sentiment analysis project is to develop a robust model that can classify user posts into various sentiment categories such as positive, negative, or neutral. This model will help MetaData in several ways:\n",
    "\n",
    "Enhancing User Experience: By understanding the sentiment of posts, MetaData can tailor the user experience, like suggesting more content that aligns with the user’s interests or mood.\n",
    "Content Moderation: Sentiment analysis can flag potentially harmful or negative content for further review, thereby maintaining a healthy online community.\n",
    "Marketing Insights: Analyzing sentiment can provide valuable insights for advertisers and partners about public opinion on various topics, products, or services.\n",
    "This can be then used on both posts and comments or any other interactions with the posts.\n",
    "\n",
    "##### 3. Framing the Problem\n",
    "For MetaData, sentiment analysis of user posts is a classic case of supervised learning, as it involves categorizing text data into predefined sentiment categories. We will train our model on a dataset where each post is labeled with a sentiment, allowing the model to learn and predict the sentiment of new, unlabeled posts. This approach aligns with the supervised learning paradigm where the input (user post) and output (sentiment label) are clearly defined. We will probably be looking at classifying into multiple classes, as we want to categorize beyond just positive/negative.\n",
    "\n",
    "##### 4. Measuring Performance\n",
    "To evaluate the performance of our sentiment analysis model, we will focus on the following metrics:\n",
    "\n",
    "- Accuracy: This will provide a basic understanding of how often our model correctly classifies a post’s sentiment.\n",
    "- Precision and Recall: These metrics are crucial for understanding the model’s performance in classifying specific sentiments, especially in a dataset that may have uneven representation of sentiments.\n",
    "- F1 Score: As a harmonic mean of precision and recall, the F1 score will help us balance the trade-off between these two metrics, which is vital in ensuring that our model is not biased toward a particular sentiment.\n",
    "- Confusion Matrix: This will help us visualize the performance of the model in terms of false positives and false negatives, giving us insights into specific areas where the model might need improvement.\n",
    "- By focusing on these metrics, we can refine our model to ensure it meets the business needs of MetaData while maintaining high standards of accuracy and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get the data\n",
    "1. Find and document where you can get the data from\n",
    "2. Get the data\n",
    "3. Check the size and type of data (time series, geographical etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Finding and Documenting Data Sources\n",
    "As part of our project at MetaData Inc., we have identified two promising datasets from Hugging Face, a renowned platform for machine learning models and datasets.\n",
    "\n",
    "- Dataset A: This dataset is relatively large, containing approximately 400,000 entries. However, it primarily includes sentences framed around personal experiences and feelings, often starting with \"I\" (e.g., \"I'm feeling quite sad and sorry for myself but I'll snap out of it soon\"). This dataset provides a deep insight into individual sentiment but may have limitations in terms of diversity and scope of expressions.\n",
    "- Dataset B: The second dataset, although smaller with around 200,000 entries, offers a broader range of content. It includes various types of text, not just personal statements, which makes it more general and potentially more representative of the diverse content on social media. However, this dataset categorizes emotions into more classes than Dataset A, which could add complexity to our analysis and model training.\n",
    "##### 2. Acquiring the Data\n",
    "We have downloaded both datasets from Hugging Face. Given the nature of our project and the need for a comprehensive understanding of user sentiments on a social media platform, having two datasets with different characteristics is beneficial. Dataset A provides depth in personal sentiment expression, while Dataset B offers breadth and variety.\n",
    "\n",
    "##### 3. Checking Size and Type of Data\n",
    "2. Dataset A 'emotion':\n",
    "- Size: Approximately 400,000 entries\n",
    "- Type: The data seems to be predominantly subjective personal statements with a focus on individual emotions and experiences. This dataset may lack diversity in sentence structure and context, as it is centered around first-person expressions.\n",
    "- This dataset is clean of unimportant collumns - there is only the text and a label to go with it.\n",
    "\n",
    "2. Dataset B 'go_emotions':\n",
    "- Size: Approximately 200,000 entries\n",
    "- Type: This dataset is more varied, not just in terms of the emotional spectrum but also in the types of sentences and contexts. It includes a wider range of expressions, which might be more reflective of general user posts on social media. However, the additional emotion categories present a challenge in terms of classification complexity.\n",
    "- This one is relatively more filled with unimportant columns for our analysis, and here we can see that there is much more categorizations for the emotions\n",
    "\n",
    "\n",
    "For our sentiment analysis project, both datasets will be crucial. Dataset A can help us understand personal sentiments in depth, while Dataset B will allow us to explore a broader range of expressions and contexts. The next steps will involve exploring these datasets in more detail and preparing them for analysis, considering their unique characteristics and how they complement each other in addressing our project's objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[K     |████████████████████████████████| 521 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-14.0.1-cp39-cp39-macosx_11_0_arm64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 5.9 MB/s eta 0:00:01█████▌        | 17.6 MB 5.9 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[K     |████████████████████████████████| 166 kB 22.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from datasets) (2.31.0)\n",
      "Collecting huggingface-hub>=0.18.0\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[K     |████████████████████████████████| 311 kB 73.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from datasets) (23.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[K     |████████████████████████████████| 174 kB 16.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from datasets) (1.25.2)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: pandas in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from datasets) (2.1.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.0-cp39-cp39-macosx_11_0_arm64.whl (386 kB)\n",
      "\u001b[K     |████████████████████████████████| 386 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs>=17.3.0\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 8.1 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.0-cp39-cp39-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.3-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 17.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.18.0->datasets) (4.7.1)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: multidict, frozenlist, yarl, attrs, async-timeout, aiosignal, pyyaml, fsspec, filelock, dill, aiohttp, xxhash, pyarrow-hotfix, pyarrow, multiprocess, huggingface-hub, datasets\n",
      "Successfully installed aiohttp-3.9.0 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 datasets-2.15.0 dill-0.3.7 filelock-3.13.1 frozenlist-1.4.0 fsspec-2023.10.0 huggingface-hub-0.19.4 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.1 pyarrow-hotfix-0.5 pyyaml-6.0.1 xxhash-3.4.1 yarl-1.9.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 3.97k/3.97k [00:00<00:00, 14.2MB/s]\n",
      "Downloading metadata: 100%|██████████| 3.28k/3.28k [00:00<00:00, 23.8MB/s]\n",
      "Downloading readme: 100%|██████████| 8.78k/8.78k [00:00<00:00, 21.9MB/s]\n",
      "Downloading data: 100%|██████████| 15.4M/15.4M [00:00<00:00, 33.0MB/s]\n",
      "Downloading data files: 100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00,  9.22it/s]\n",
      "Generating train split: 100%|██████████| 416809/416809 [00:05<00:00, 80618.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "emotion_dataset = load_dataset(\"dair-ai/emotion\", \"unsplit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading emotion dataset\n",
    "import pandas as pd\n",
    "\n",
    "emotion_raw = emotion_dataset['train']\n",
    "emotion_raw_df = pd.DataFrame(emotion_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i feel awful about it too because it s my job ...      0\n",
       "1                              im alone i feel awful      0\n",
       "2  ive probably mentioned this before but i reall...      1\n",
       "3           i was feeling a little low few days back      0\n",
       "4  i beleive that i am much more sensitive to oth...      2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_dataset = load_dataset(\"go_emotions\", \"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading go_emotions dataset\n",
    "import pandas as pd\n",
    "\n",
    "go_emotions_raw = go_emotions_dataset['train']\n",
    "go_emotions_raw_df = pd.DataFrame(go_emotions_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  amusement  anger  \\\n",
       "0  1.548381e+09         1                 False           0          0      0   \n",
       "1  1.548084e+09        37                 False           0          0      0   \n",
       "2  1.546428e+09        37                 False           0          0      0   \n",
       "3  1.547965e+09        18                 False           0          0      0   \n",
       "4  1.546669e+09         2                 False           0          0      0   \n",
       "\n",
       "   annoyance  approval  caring  confusion  curiosity  desire  disappointment  \\\n",
       "0          0         0       0          0          0       0               0   \n",
       "1          0         0       0          0          0       0               0   \n",
       "2          0         0       0          0          0       0               0   \n",
       "3          0         0       0          0          0       0               0   \n",
       "4          0         0       0          0          0       0               0   \n",
       "\n",
       "   disapproval  disgust  embarrassment  excitement  fear  gratitude  grief  \\\n",
       "0            0        0              0           0     0          0      0   \n",
       "1            0        0              0           0     0          0      0   \n",
       "2            0        0              0           0     0          0      0   \n",
       "3            0        0              0           0     0          0      0   \n",
       "4            0        0              0           0     0          0      0   \n",
       "\n",
       "   joy  love  nervousness  optimism  pride  realization  relief  remorse  \\\n",
       "0    0     0            0         0      0            0       0        0   \n",
       "1    0     0            0         0      0            0       0        0   \n",
       "2    0     0            0         0      0            0       0        0   \n",
       "3    0     1            0         0      0            0       0        0   \n",
       "4    0     0            0         0      0            0       0        0   \n",
       "\n",
       "   sadness  surprise  neutral  \n",
       "0        1         0        0  \n",
       "1        0         0        0  \n",
       "2        0         0        1  \n",
       "3        0         0        0  \n",
       "4        0         0        1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "go_emotions_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_raw_df.to_csv('../exports/emotion_raw.csv')\n",
    "go_emotions_raw_df.to_csv('../exports/go_emotions_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling for better exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 416809\n",
      "Slimmed down size: 20840\n"
     ]
    }
   ],
   "source": [
    "## dataset down-sampling\n",
    "\n",
    "fraction = 0.05\n",
    "\n",
    "emotion_df_slim = emotion_raw_df.sample(frac=fraction)\n",
    "\n",
    "print(f\"Original size: {len(emotion_raw_df)}\")\n",
    "print(f\"Slimmed down size: {len(emotion_df_slim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 211225\n",
      "Slimmed down size: 21122\n"
     ]
    }
   ],
   "source": [
    "## dataset down-sampling\n",
    "\n",
    "fraction = 0.1\n",
    "\n",
    "go_emotions_df_slim = go_emotions_raw_df.sample(frac=fraction)\n",
    "\n",
    "print(f\"Original size: {len(go_emotions_raw_df)}\")\n",
    "print(f\"Slimmed down size: {len(go_emotions_df_slim)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df_slim.to_csv('../exports/emotion_slim.csv')\n",
    "go_emotions_df_slim.to_csv('../exports/go_emotions_slim.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Explore the data\n",
    "1. Create a copy of the data for explorations (sampling it down to a manageable size if necessary)\n",
    "2. Create a Jupyter notebook to keep a record of your data exploration\n",
    "3. Study each feature and its characteristics:\n",
    "    * Name\n",
    "    * Type (categorical, int/float, bounded/unbounded, text, structured, etc)\n",
    "    * Percentage of missing values\n",
    "    * Check for outliers, rounding errors etc\n",
    "4. For supervised learning tasks, identify the target(s)\n",
    "5. Visualise the data\n",
    "6. Study the correlations between features\n",
    "7. Identify the promising transformations you may want to apply (e.g. convert skewed targets to normal via a log transformation)\n",
    "8. Document what you have learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>rater_id</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>eew5j0j</td>\n",
       "      <td>Brdd9</td>\n",
       "      <td>nrl</td>\n",
       "      <td>t3_ajis4z</td>\n",
       "      <td>t1_eew18eq</td>\n",
       "      <td>1.548381e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>eemcysk</td>\n",
       "      <td>TheGreen888</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>t3_ai4q37</td>\n",
       "      <td>1.548084e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>ed2mah1</td>\n",
       "      <td>Labalool</td>\n",
       "      <td>confessions</td>\n",
       "      <td>t3_abru74</td>\n",
       "      <td>t1_ed2m7g7</td>\n",
       "      <td>1.546428e+09</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>eeibobj</td>\n",
       "      <td>MrsRobertshaw</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>t3_ahulml</td>\n",
       "      <td>1.547965e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>eda6yn6</td>\n",
       "      <td>American_Fascist713</td>\n",
       "      <td>starwarsspeculation</td>\n",
       "      <td>t3_ackt2f</td>\n",
       "      <td>t1_eda65q2</td>\n",
       "      <td>1.546669e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1   >sexuality shouldn’t be a grouping category I...  eemcysk   \n",
       "2     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "3                                 Man I love reddit.  eeibobj   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1          TheGreen888     unpopularopinion  t3_ai4q37   t3_ai4q37   \n",
       "2             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "3        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "4  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "\n",
       "    created_utc  rater_id  example_very_unclear  admiration  amusement  anger  \\\n",
       "0  1.548381e+09         1                 False           0          0      0   \n",
       "1  1.548084e+09        37                 False           0          0      0   \n",
       "2  1.546428e+09        37                 False           0          0      0   \n",
       "3  1.547965e+09        18                 False           0          0      0   \n",
       "4  1.546669e+09         2                 False           0          0      0   \n",
       "\n",
       "   annoyance  approval  caring  confusion  curiosity  desire  disappointment  \\\n",
       "0          0         0       0          0          0       0               0   \n",
       "1          0         0       0          0          0       0               0   \n",
       "2          0         0       0          0          0       0               0   \n",
       "3          0         0       0          0          0       0               0   \n",
       "4          0         0       0          0          0       0               0   \n",
       "\n",
       "   disapproval  disgust  embarrassment  excitement  fear  gratitude  grief  \\\n",
       "0            0        0              0           0     0          0      0   \n",
       "1            0        0              0           0     0          0      0   \n",
       "2            0        0              0           0     0          0      0   \n",
       "3            0        0              0           0     0          0      0   \n",
       "4            0        0              0           0     0          0      0   \n",
       "\n",
       "   joy  love  nervousness  optimism  pride  realization  relief  remorse  \\\n",
       "0    0     0            0         0      0            0       0        0   \n",
       "1    0     0            0         0      0            0       0        0   \n",
       "2    0     0            0         0      0            0       0        0   \n",
       "3    0     1            0         0      0            0       0        0   \n",
       "4    0     0            0         0      0            0       0        0   \n",
       "\n",
       "   sadness  surprise  neutral  \n",
       "0        1         0        0  \n",
       "1        0         0        0  \n",
       "2        0         0        1  \n",
       "3        0         0        0  \n",
       "4        0         0        1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go_emotions_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_cleaned_df = go_emotions_raw_df.copy()\n",
    "\n",
    "go_emotions_cleaned_df.drop(columns=['created_utc', \n",
    "                                 'rater_id', \n",
    "                                 'id', \n",
    "                                 'author', \n",
    "                                 'subreddit', \n",
    "                                 'link_id',\n",
    "                                 'parent_id'], \n",
    "                        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_emotions_cleaned_df = go_emotions_cleaned_df[go_emotions_cleaned_df['example_very_unclear'] != True]\n",
    "go_emotions_cleaned_df.drop(columns=['example_very_unclear'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disapproval</th>\n",
       "      <th>disgust</th>\n",
       "      <th>embarrassment</th>\n",
       "      <th>excitement</th>\n",
       "      <th>fear</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>grief</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  admiration  amusement  \\\n",
       "0                                    That game hurt.           0          0   \n",
       "1   >sexuality shouldn’t be a grouping category I...           0          0   \n",
       "2     You do right, if you don't care then fuck 'em!           0          0   \n",
       "3                                 Man I love reddit.           0          0   \n",
       "4  [NAME] was nowhere near them, he was by the Fa...           0          0   \n",
       "\n",
       "   anger  annoyance  approval  caring  confusion  curiosity  desire  \\\n",
       "0      0          0         0       0          0          0       0   \n",
       "1      0          0         0       0          0          0       0   \n",
       "2      0          0         0       0          0          0       0   \n",
       "3      0          0         0       0          0          0       0   \n",
       "4      0          0         0       0          0          0       0   \n",
       "\n",
       "   disappointment  disapproval  disgust  embarrassment  excitement  fear  \\\n",
       "0               0            0        0              0           0     0   \n",
       "1               0            0        0              0           0     0   \n",
       "2               0            0        0              0           0     0   \n",
       "3               0            0        0              0           0     0   \n",
       "4               0            0        0              0           0     0   \n",
       "\n",
       "   gratitude  grief  joy  love  nervousness  optimism  pride  realization  \\\n",
       "0          0      0    0     0            0         0      0            0   \n",
       "1          0      0    0     0            0         0      0            0   \n",
       "2          0      0    0     0            0         0      0            0   \n",
       "3          0      0    0     1            0         0      0            0   \n",
       "4          0      0    0     0            0         0      0            0   \n",
       "\n",
       "   relief  remorse  sadness  surprise  neutral  \n",
       "0       0        0        1         0        0  \n",
       "1       0        0        0         0        0  \n",
       "2       0        0        0         0        1  \n",
       "3       0        0        0         0        0  \n",
       "4       0        0        0         0        1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "go_emotions_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each label within each dataset\n",
    "label_dataset_counts = go_emotions_cleaned_df.groupby(['dataset', 'label']).size().unstack(fill_value=0)\n",
    "\n",
    "label_dataset_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "go_emotions has these emotions:\n",
    "- admiration\n",
    "- amusement\n",
    "- anger\n",
    "- annoyance\n",
    "- approval\n",
    "- caring\n",
    "- confusion\n",
    "- curiosity\n",
    "- desire\n",
    "- disappointment\n",
    "- disapproval\n",
    "- disgust\n",
    "- embarrassment\n",
    "- excitement\n",
    "- fear\n",
    "- gratitude\n",
    "- grief\n",
    "- joy\n",
    "- love\n",
    "- nervousness\n",
    "- optimism\n",
    "- pride\n",
    "- realization\n",
    "- relief\n",
    "- remorse\n",
    "- sadness\n",
    "- surprise\n",
    "- neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0: 'sadness'\n",
    "- 1: 'joy'\n",
    "- 2: 'love'\n",
    "- 3: 'anger'\n",
    "- 4: 'fear'\n",
    "- 5: 'surprise'\n",
    "\n",
    "### possible mapping the go_emotions to the second shorter categories:\n",
    "\n",
    "### 0: 'sadness'\n",
    "- disappointment\n",
    "- grief\n",
    "- remorse\n",
    "- sadness\n",
    "\n",
    "### 1: 'joy'\n",
    "- amusement\n",
    "- excitement\n",
    "- joy\n",
    "- optimism\n",
    "\n",
    "### 2: 'love'\n",
    "- caring\n",
    "- love\n",
    "\n",
    "### 3: 'anger'\n",
    "- anger\n",
    "- annoyance\n",
    "- disapproval (could be related to anger)\n",
    "- disgust (could be related to anger)\n",
    "\n",
    "### 4: 'fear'\n",
    "- fear\n",
    "- nervousness (could be related to fear)\n",
    "\n",
    "### 5: 'surprise'\n",
    "- surprise\n",
    "\n",
    "\n",
    "not categorized:\n",
    "admiration\n",
    "approval\n",
    "confusion\n",
    "curiosity\n",
    "desire\n",
    "embarrassment\n",
    "gratitude\n",
    "pride\n",
    "realization\n",
    "relief\n",
    "neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Separate notebook with this step - ./3-data-exploration.ipynb](./3-data-exploration.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prepare the data\n",
    "Notes:\n",
    "* Work on copies of the data (keep the original dataset intact).\n",
    "* Write functions for all data transformations you apply, for three reasons:\n",
    "    * So you can easily prepare the data the next time you run your code\n",
    "    * So you can apply these transformations in future projects\n",
    "    * To clean and prepare the test set\n",
    "    \n",
    "    \n",
    "1. Data cleaning:\n",
    "    * Fix or remove outliers (or keep them)\n",
    "    * Fill in missing values (e.g. with zero, mean, median, regression ...) or drop their rows (or columns)\n",
    "2. Feature selection (optional):\n",
    "    * Drop the features that provide no useful information for the task (e.g. a customer ID is usually useless for modelling).\n",
    "3. Feature engineering, where appropriate:\n",
    "    * Discretize continuous features\n",
    "    * Use one-hot encoding if/when relevant\n",
    "    * Add promising transformations of features (e.g. $\\log(x)$, $\\sqrt{x}$, $x^2$, etc)\n",
    "    * Aggregate features into promising new features\n",
    "4. Feature scaling: standardise or normalise features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Separate notebook with this step - ./4-preparing-data.ipynb](./4-preparing-data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Short-list promising models\n",
    "We expect you to do some additional research and train at **least one model per team member**.\n",
    "\n",
    "1. Train mainly quick and dirty models from different categories (e.g. linear, SVM, Random Forests etc) using default parameters\n",
    "2. Measure and compare their performance\n",
    "3. Analyse the most significant variables for each algorithm\n",
    "4. Analyse the types of errors the models make\n",
    "5. Have a quick round of feature selection and engineering if necessary\n",
    "6. Have one or two more quick iterations of the five previous steps\n",
    "7. Short-list the top three to five most promising models, preferring models that make different types of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Separate notebook with this step - ./5-training-models.ipynb](./5-training-models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fine-tune the system\n",
    "1. Fine-tune the hyperparameters\n",
    "2. Once you are confident about your final model, measure its performance on the test set to estimate the generalisation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Present your solution\n",
    "1. Document what you have done\n",
    "2. Create a nice 15 minute video presentation with slides\n",
    "    * Make sure you highlight the big picture first\n",
    "3. Explain why your solution achieves the business objective\n",
    "4. Don't forget to present interesting points you noticed along the way:\n",
    "    * Describe what worked and what did not\n",
    "    * List your assumptions and you model's limitations\n",
    "5. Ensure your key findings are communicated through nice visualisations or easy-to-remember statements (e.g. \"the median income is the number-one predictor of housing prices\")\n",
    "6. Upload the presentation to some online platform, e.g. YouTube or Vimeo, and supply a link to the video in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Géron, A. 2017, *Hands-On Machine Learning with Scikit-Learn and Tensorflow*, Appendix B, O'Reilly Media, Inc., Sebastopol."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
