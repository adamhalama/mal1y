{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Short-list promising models\n",
    "We expect you to do some additional research and train at **least one model per team member**.\n",
    "\n",
    "1. Train mainly quick and dirty models from different categories (e.g. linear, SVM, Random Forests etc) using default parameters\n",
    "2. Measure and compare their performance\n",
    "3. Analyse the most significant variables for each algorithm\n",
    "4. Analyse the types of errors the models make\n",
    "5. Have a quick round of feature selection and engineering if necessary\n",
    "6. Have one or two more quick iterations of the five previous steps\n",
    "7. Short-list the top three to five most promising models, preferring models that make different types of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: keras in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.14.0)\n",
      "Requirement already satisfied: torch in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.1.1)\n",
      "Requirement already satisfied: tqdm in /Users/jaa/Library/Python/3.9/lib/python/site-packages (4.66.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: filelock in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in /Users/jaa/Library/Python/3.9/lib/python/site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in /Users/jaa/Library/Python/3.9/lib/python/site-packages (2.1.1)\n",
      "Requirement already satisfied: networkx in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: jinja2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: requests in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: numpy in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jaa/Library/Python/3.9/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# installing dependencies\n",
    "!pip3 install pandas keras torch tqdm\n",
    "\n",
    "# !pip3 install --pre torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data as dataframes\n",
    "import pandas as pd\n",
    "\n",
    "emotions_df_train_ready = pd.read_csv('../data/emotions_train_ready.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### just to not forget the mapping\n",
    "\n",
    "- 0: 'sadness'\n",
    "- 1: 'joy'\n",
    "- 2: 'love'\n",
    "- 3: 'anger'\n",
    "- 4: 'fear'\n",
    "- 5: 'surprise'\n",
    "- 6: 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0  text                                                                                                                                                                                     label\n",
       "0           Yeah, but nobody takes McD's hamburgers seriously.                                                                                                                                       1        1\n",
       "399325      That's no hero to me.                                                                                                                                                                    0        1\n",
       "399309      i didnt grab anything too small and i could still feel how tender it was but positive movement is a very good thing                                                                      2        1\n",
       "399310      i feel pretty good considering                                                                                                                                                           1        1\n",
       "399311      i may feel lonely sometimes i am never truly alone                                                                                                                                       0        1\n",
       "                                                                                                                                                                                                             ..\n",
       "199658      i have this horrible feeling that im being bothered                                                                                                                                      3        1\n",
       "199659      [NAME] ruled out due to injury. [NAME] starts. [NAME] to bench. Doubtful of a win now.                                                                                                   6        1\n",
       "199660      i regret that life did not give me a chance to kiss you goodnight to hold u tight and say everything will be fine when you are feeling low                                               0        1\n",
       "199661      i get the very uncomfortable feeling that many americans are in some respects eager to latch onto going green as an easy way to do something that makes them feel good about themselves  1        1\n",
       "598970      i feel a lot less shaken scared about seeing her                                                                                                                                         4        1\n",
       "Name: count, Length: 598971, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_df_train_ready.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yeah', 'but', 'nobody', 'takes', 'McD', 's', 'hamburgers', 'seriously', '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Custom tokenization using regular expressions\n",
    "def custom_tokenize(text):\n",
    "    # Regular expression for splitting on whitespace and keeping punctuation\n",
    "    tokens = re.findall(r\"\\b\\w+\\b|[!?.]\", text)\n",
    "    return tokens\n",
    "\n",
    "# Applying custom tokenization to the entire dataset\n",
    "tokenized_texts = [custom_tokenize(text) for text in emotions_df_train_ready['text']]\n",
    "\n",
    "# Example of tokenized text\n",
    "tokenized_texts_example = tokenized_texts[0]\n",
    "tokenized_texts_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Flatten the list of tokenized texts\n",
    "all_tokens = [token for text in tokenized_texts for token in text]\n",
    "vocabulary = set(all_tokens)\n",
    "\n",
    "# Mapping tokens to integers\n",
    "token_to_int = {token: i+1 for i, token in enumerate(vocabulary)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum vocabulary size\n",
    "max_vocab_size = 10000  # You can adjust this number as needed\n",
    "\n",
    "# Count the frequency of each token\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "# Keep only the most frequent tokens\n",
    "most_common_tokens = [token for token, count in token_counts.most_common(max_vocab_size)]\n",
    "\n",
    "# Create a new token-to-integer mapping, including a token for unknown words\n",
    "token_to_int = {token: i+1 for i, token in enumerate(most_common_tokens)}\n",
    "token_to_int[\"<UNK>\"] = len(most_common_tokens) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the tokenized texts using the updated mapping\n",
    "encoded_sequences = []\n",
    "for text in tokenized_texts:\n",
    "    encoded_text = [token_to_int.get(token, token_to_int[\"<UNK>\"]) for token in text]\n",
    "    encoded_sequences.append(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Finding the maximum sequence length\n",
    "max_seq_length = max(len(seq) for seq in encoded_sequences)\n",
    "\n",
    "# Padding the sequences\n",
    "padded_sequences = np.array([seq + [0]*(max_seq_length - len(seq)) for seq in encoded_sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the labels\n",
    "labels = emotions_df_train_ready['label'].values\n",
    "\n",
    "# One-hot encoding the labels\n",
    "num_classes = len(np.unique(labels))\n",
    "one_hot_labels = np.eye(num_classes)[labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and the rest\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    padded_sequences, one_hot_labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Further splitting the training set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src2 = self.multihead_attn(src, src, src, attn_mask=src_mask,\n",
    "                                   key_padding_mask=src_key_padding_mask)[0]\n",
    "        src = src + self.dropout1(src2)\n",
    "        src = self.norm1(src)\n",
    "        src2 = self.linear2(self.dropout(F.relu(self.linear1(src))))\n",
    "        src = src + self.dropout2(src2)\n",
    "        src = self.norm2(src)\n",
    "        return src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, ntoken, d_model, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.transformer_layers = nn.ModuleList([TransformerBlock(d_model, nhead, nhid, dropout) for _ in range(nlayers)])\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        for mod in self.transformer_layers:\n",
    "            src = mod(src, src_mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        output = self.decoder(src)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(most_common_tokens) + 2 # size of vocabulary\n",
    "d_model = 128 # embedding dimension\n",
    "nhead = 4     # number of heads in multi-head attention models\n",
    "nhid = 512   # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 4   # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "dropout = 0.1 # dropout probability\n",
    "\n",
    "model = TransformerModel(ntokens, d_model, nhead, nhid, nlayers, dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Create a custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Instantiate the dataset\n",
    "dataset = TextDataset(X_train, y_train)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "## Switch to M! GPU acceleration \n",
    "\n",
    "import torch\n",
    "\n",
    "# Check if MPS (Apple's M1 GPU) is available and use it; otherwise, use CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Average Loss: 4.5185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15, Average Loss: 4.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15, Average Loss: 0.6640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15, Average Loss: 0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15, Average Loss: 0.5003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15, Average Loss: 0.4817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15, Average Loss: 0.4574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15, Average Loss: 0.4568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15, Average Loss: 0.4606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15, Average Loss: 0.4376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15, Average Loss: 0.4225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15, Average Loss: 0.4356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15, Average Loss: 0.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15, Average Loss: 0.4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15, Average Loss: 0.4255\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "        nputs = inputs.float()  # Ensure inputs are float32\n",
    "        labels = labels.long()   # Ensure labels are long\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}')\n",
    "    \n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'path_to_save_model.pth')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
